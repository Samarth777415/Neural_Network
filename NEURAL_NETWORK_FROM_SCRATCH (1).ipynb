{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5BVhbfRHbUw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Activation:\n",
        "    @staticmethod\n",
        "    def sigmoid(x):\n",
        "        x = np.clip(x, -500, 500)\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid_derivative(x):\n",
        "        sigmoid_x = Activation.sigmoid(x)\n",
        "        return sigmoid_x * (1 - sigmoid_x)\n",
        "\n",
        "    @staticmethod\n",
        "    def relu(x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    @staticmethod\n",
        "    def relu_derivative(x):\n",
        "        return np.where(x > 0, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Layer:\n",
        "    def __init__(self, input_size, output_size, activation=None, init_method=\"random\", weights=None, biases=None):\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        if weights is not None and biases is not None:\n",
        "            self.weights = np.array(weights)\n",
        "            self.biases = np.array(biases)\n",
        "        else:\n",
        "            self.init_weights(input_size, output_size, init_method)\n",
        "            self.biases = np.zeros((1, output_size))\n",
        "\n",
        "        # Set activation function\n",
        "        self.set_activation(activation)\n",
        "\n",
        "    def init_weights(self, input_size, output_size, method=\"random\"):\n",
        "        if method == \"random\":\n",
        "            self.weights = np.random.randn(input_size, output_size) * 0.1\n",
        "        elif method == \"xavier\":\n",
        "            self.weights = np.random.randn(input_size, output_size) * np.sqrt(1 / input_size)\n",
        "        elif method == \"he\":\n",
        "            self.weights = np.random.randn(input_size, output_size) * np.sqrt(2 / input_size)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown initialization method. Use 'random', 'xavier', or 'he'.\")\n",
        "\n",
        "    def set_activation(self, activation):\n",
        "        activations = {\n",
        "            \"sigmoid\": (Activation.sigmoid, Activation.sigmoid_derivative),\n",
        "            \"relu\": (Activation.relu, Activation.relu_derivative)\n",
        "        }\n",
        "        self.activation, self.activation_derivative = activations.get(activation, (None, None))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        self.z = np.dot(inputs, self.weights) + self.biases\n",
        "        self.a = self.activation(self.z) if self.activation else self.z\n",
        "        return self.a\n",
        "\n",
        "    def backward(self, dA, learning_rate):\n",
        "        dZ = dA * (self.activation_derivative(self.z) if self.activation_derivative else 1)\n",
        "        dW = np.dot(self.inputs.T, dZ)\n",
        "        dB = np.sum(dZ, axis=0, keepdims=True)\n",
        "        dA_prev = np.dot(dZ, self.weights.T)\n",
        "\n",
        "        # Update weights and biases\n",
        "        self.weights -= learning_rate * dW\n",
        "        self.biases -= learning_rate * dB\n",
        "\n",
        "        return dA_prev\n"
      ],
      "metadata": {
        "id": "UAh6nd2AHyh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self):\n",
        "        self.layers = []\n",
        "\n",
        "    def add_layer(self, input_size, output_size, activation=None, init_method=\"random\", weights=None, biases=None):\n",
        "        \"\"\"Add a new layer to the network.\"\"\"\n",
        "        self.layers.append(Layer(input_size, output_size, activation, init_method, weights, biases))\n",
        "\n",
        "    def forward(self, X):\n",
        "        for layer in self.layers:\n",
        "            X = layer.forward(X)\n",
        "        return X\n",
        "\n",
        "    def backward(self, X, Y, learning_rate):\n",
        "        output_layer = self.layers[-1]\n",
        "        dA = (output_layer.a - Y)\n",
        "\n",
        "        for layer in reversed(self.layers):\n",
        "            dA = layer.backward(dA, learning_rate)\n",
        "\n",
        "    def train(self, X, Y, epochs=1000, learning_rate=0.01):\n",
        "        for epoch in range(epochs):\n",
        "            output = self.forward(X)\n",
        "            self.backward(X, Y, learning_rate)\n",
        "            loss = np.mean((output - Y) ** 2)\n",
        "            if epoch % 100 == 0:\n",
        "                print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Forward pass to get predictions\"\"\"\n",
        "        output = X\n",
        "        for layer in self.layers:\n",
        "            output = layer.forward(output)\n",
        "        return output\n",
        "\n",
        "    def summary(self):\n",
        "        print(\"\\n\" + \"=\" * 40)\n",
        "        print(\"Neural Network Summary\")\n",
        "        print(\"=\" * 40)\n",
        "        print(f\"{'Layer':<10}{'Input Shape':<15}{'Output Shape':<15}{'Params'}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        total_params = 0\n",
        "        input_shape = None\n",
        "\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            input_shape = (None, layer.input_size) if input_shape is None else (None, self.layers[i-1].output_size)\n",
        "            output_shape = (None, layer.output_size)\n",
        "\n",
        "            num_params = (layer.input_size * layer.output_size) + layer.output_size\n",
        "            total_params += num_params\n",
        "\n",
        "            print(f\"{i+1:<10}{str(input_shape):<15}{str(output_shape):<15}{num_params}\")\n",
        "\n",
        "        print(\"=\" * 40)\n",
        "        print(f\"Total Parameters: {total_params}\")\n",
        "        print(\"=\" * 40)\n"
      ],
      "metadata": {
        "id": "8shGFyFPH1jA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "      \"\"\"Calculate accuracy by comparing true labels with predicted labels.\"\"\"\n",
        "      correct = np.sum(y_true == y_pred)\n",
        "      total = len(y_true)\n",
        "      return correct / total"
      ],
      "metadata": {
        "id": "po1YarzBO-qD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XOR Data\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "# Create Model\n",
        "nn = NeuralNetwork()\n",
        "nn.add_layer(2, 4, \"sigmoid\")\n",
        "nn.add_layer(4, 1, \"sigmoid\")\n",
        "\n",
        "# Train\n",
        "\n",
        "nn.train(X, Y, epochs=1000, learning_rate=0.01)\n",
        "\n",
        "# Test\n",
        "print(nn.forward(X))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR1PYwLpH5vx",
        "outputId": "374ce7e7-3c4f-403e-eedd-5a8d1b530077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.2500\n",
            "Epoch 100, Loss: 0.2500\n",
            "Epoch 200, Loss: 0.2500\n",
            "Epoch 300, Loss: 0.2500\n",
            "Epoch 400, Loss: 0.2500\n",
            "Epoch 500, Loss: 0.2500\n",
            "Epoch 600, Loss: 0.2500\n",
            "Epoch 700, Loss: 0.2500\n",
            "Epoch 800, Loss: 0.2500\n",
            "Epoch 900, Loss: 0.2500\n",
            "[[0.49998923]\n",
            " [0.50016451]\n",
            " [0.49986853]\n",
            " [0.50004564]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-NhWx50QpLf",
        "outputId": "95c1477f-4670-4d2b-fc27-1e8e6e847e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "Neural Network Summary\n",
            "========================================\n",
            "Layer     Input Shape    Output Shape   Params\n",
            "----------------------------------------\n",
            "1         (None, 2)      (None, 4)      12\n",
            "2         (None, 4)      (None, 1)      5\n",
            "========================================\n",
            "Total Parameters: 17\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1st Question\n",
        "custom_weights_1 = np.array([[0.15, 0.25], [0.2, 0.3]])\n",
        "custom_biases_1 = np.array([[0.35, 0.35]])\n",
        "\n",
        "custom_weights_2 = np.array([[0.4, 0.2], [0.45, 0.55]])\n",
        "custom_biases_2 = np.array([[0.16, 0.16]])\n",
        "\n",
        "nn1 = NeuralNetwork()\n",
        "nn1.add_layer(2, 2, \"sigmoid\", weights=custom_weights_1, biases=custom_biases_1)\n",
        "nn1.add_layer(2, 2, \"sigmoid\", weights=custom_weights_2, biases=custom_biases_2)\n",
        "XN=np.array([0.05,0.1])\n",
        "ans=nn1.predict(XN)\n",
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdVYgKOWIGOd",
        "outputId": "3c4e8eda-863a-4621-cf94-1710818fc9f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.66058583 0.64724255]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2nd Question\n",
        "import numpy as np\n",
        "\n",
        "# Define training data\n",
        "X = np.array([[1, 1], [0, 1]])  # Inputs\n",
        "Y = np.array([[0], [1]])        # Targets\n",
        "\n",
        "# Given initial weights and biases\n",
        "W1 = np.array([[0.5, 0.2], [-0.3, 0.5]])\n",
        "B1 = np.array([[0.1, 0.3]])\n",
        "\n",
        "W2 = np.array([[0.6], [-0.4]])\n",
        "B2 = np.array([[0.8]])\n",
        "\n",
        "# Create Neural Network\n",
        "nn2 = NeuralNetwork()\n",
        "\n",
        "# Add layers with given weights and biases\n",
        "nn2.add_layer(2, 2, \"relu\", weights=W1, biases=B1)  # Hidden layer\n",
        "nn2.add_layer(2, 1, \"relu\", weights=W2, biases=B2)  # Output layer\n",
        "\n",
        "# Train for 5 epochs\n",
        "nn2.train(X, Y, epochs=500, learning_rate=0.5)\n",
        "\n",
        "# Print updated weights and biases\n",
        "print(\"\\nUpdated Weights:\")\n",
        "for i, layer in enumerate(nn2.layers):\n",
        "    print(f\"Layer {i+1} Weights:\\n\", layer.weights)\n",
        "    print(f\"Layer {i+1} Biases:\\n\", layer.biases)\n",
        "\n",
        "# Predict on training data (to check accuracy)\n",
        "train_predictions = nn2.predict(X)\n",
        "train_predicted_classes = (train_predictions > 0.5).astype(int)\n",
        "\n",
        "# Compute accuracy\n",
        "train_accuracy = accuracy(Y, train_predicted_classes)\n",
        "print(f\"\\nTraining Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Predict on new test data\n",
        "X_new = np.array([[1, 0], [0, 0], [1, 1], [0, 1],[0,1],[1,1]])\n",
        "predictions = nn2.predict(X_new)\n",
        "predicted_classes = (predictions > 0.5).astype(int)\n",
        "\n",
        "# Print predictions and accuracy\n",
        "print(\"\\nPredictions on Test Data:\")\n",
        "print(predicted_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1FAdWazJkl8",
        "outputId": "06932214-7c6e-47ce-b4c6-0bb32552895b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.3034\n",
            "Epoch 100, Loss: 0.0000\n",
            "Epoch 200, Loss: 0.0000\n",
            "Epoch 300, Loss: 0.0000\n",
            "Epoch 400, Loss: 0.0000\n",
            "\n",
            "Updated Weights:\n",
            "Layer 1 Weights:\n",
            " [[ 0.326       1.176439  ]\n",
            " [-0.474       0.06403951]]\n",
            "Layer 1 Biases:\n",
            " [[-0.074      -0.13596049]]\n",
            "Layer 2 Weights:\n",
            " [[ 0.513     ]\n",
            " [-0.92605023]]\n",
            "Layer 2 Biases:\n",
            " [[1.]]\n",
            "\n",
            "Training Accuracy: 100.00%\n",
            "\n",
            "Predictions on Test Data:\n",
            "[[0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0BpwOsQGbQxD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}